---
id: masks
title: 遮罩功能
---

## 画面变动遮罩 {#motion-masks}

画面变动遮罩（也叫画面变动遮罩）用于防止不需要的画面变动类型触发检测。可以打开调试视图（设置 --> 调试）并启用"画面变动框"选项，观察哪些区域经常被误检测为画面变动。例如，你可能需要遮罩掉时间戳、天空、屋顶等区域。

请注意，这种遮罩**仅阻止画面变动检测**，如果物体/目标检测是由未遮罩区域的画面变动触发的，它**不会阻止目标被检测到**。画面变动信息也会在目标追踪过程中用于优化下一帧的物体/目标检测区域。**过度使用遮罩会使目标追踪变得更加困难。**

你可能不需要使用画面变动遮罩，具体信息可参阅[进一步说明](#further-clarification)。

## 物体/目标过滤遮罩 {#object-filter-masks}

物体/目标过滤遮罩用于根据位置过滤特定目标类型的误报。这些遮罩应该用于过滤掉不可能出现某类目标的区域。系统会评估检测物品/目标边界框的**底部中心点**是否位于遮罩区域内。如果在遮罩区域内，则会被视为误报。例如，你可能需要对人物检测遮罩屋顶、墙壁、天空、树顶等区域。对于车辆，遮罩掉街道或车道以外的区域可以告诉 Frigate 院子里的任何检测都是误报。

物体/目标过滤遮罩可用于过滤固定位置顽固的误报。例如，某棵树的底部可能经常被误检测为人。下图展示了一个物体/目标过滤遮罩示例（红色阴影区域），覆盖了通常检测到底部中心点的位置，以精确过滤该位置的人物检测。

![目标遮罩](/img/bottom-center-mask.jpg)

## 使用遮罩创建工具 {#using-the-mask-creator}

创建多边形遮罩的步骤：

1. 访问 Web 界面
2. 点击齿轮图标打开"设置"
3. 选择"遮罩/区域编辑器"
4. 在右上角选择要创建遮罩或区域的摄像头
5. 点击要创建的遮罩或区域类型下的加号图标
6. 在摄像头最新画面上点击创建遮罩区域的多边形顶点。点击第一个顶点闭合多边形。
7. 完成遮罩创建后，点击保存

配置文件将更新为遮罩/区域的相对坐标：

```yaml
motion:
  mask: "0.000,0.427,0.002,0.000,0.999,0.000,0.999,0.781,0.885,0.456,0.700,0.424,0.701,0.311,0.507,0.294,0.453,0.347,0.451,0.400"
```

配置中可以列出多个遮罩：

```yaml
motion:
  mask:
    - 0.239,1.246,0.175,0.901,0.165,0.805,0.195,0.802
    - 0.000,0.427,0.002,0.000,0.999,0.000,0.999,0.781,0.885,0.456
```

### 进一步说明 {#further-clarification}

这是对[Reddit 上提出问题](https://www.reddit.com/r/homeautomation/comments/ppxdve/replacing_my_doorbell_with_a_security_camera_a_6/hd876w4?utm_source=share&utm_medium=web2x&context=3)的回应：

了解 Frigate 如何结合使用画面变动检测和物体/目标检测会很有帮助。

首先，Frigate 使用画面变动检测作为初步检查，判断画面中是否有值得进行物体/目标检测的活动。

一旦检测到画面变动，它会尝试将附近的画面变动区域分组，希望能识别出画面中值得检测的矩形区域。这些就是你在调试视图中看到的红色"画面变动框"。

确定画面变动区域后，Frigate 会创建一个"区域"（调试视图中的绿色框）来运行物体/目标检测。模型是在方形图像上训练的，所以这些区域总是正方形。它会在画面变动区域周围添加边距，希望能捕捉到填充大部分检测图像的画面变动目标裁剪视图，同时不会切断任何部分。如果正在追踪目标，它还会考虑前一帧边界框的位置。

运行物体/目标检测后，如果检测到似乎被切断的目标，Frigate 会重新调整区域并在同一帧上再次运行物体/目标检测以获得更好的视角。

所有这些处理都会针对每个画面变动区域和追踪目标进行。

> 你是否只是说任何类型的检测的初始触发只会发生在未遮罩区域，但一旦触发发生，遮罩就变得无关紧要，物体/目标检测优先？

基本上是的。不过我不会描述为物体/目标检测优先。画面变动遮罩只是阻止这些区域被计为画面变动。这些遮罩不会以任何方式修改传递给物体/目标检测的区域，因此你绝对可以在画面变动遮罩区域中检测到目标。

> 如果是这样，这对我来说是完全预期和直观的行为。因为显然如果一只"脚"开始画面变动检测，相机应该能够检查它是否是一个完整的人，然后它完全进入区域。文档暗示这是行为，所以我也不能理解为什么这总体上对物体/目标检测有害。

当只有一只脚触发画面变动时，Frigate 会放大并只查看这只脚。如果这甚至符合一个人的特征，它会确定目标被切断并再次查看，直到放大到足以找到整个人。

这对 Frigate 追踪移动目标的方式也有害。前一帧边界框附近的画面变动用于智能确定下一帧中区域应该在哪里。遮罩过多会阻碍追踪，如果目标从未遮罩区域进入完全遮罩区域，它们基本上会消失，如果离开遮罩区域，将被视为"新"目标。这很重要，因为 Frigate 在追踪目标时使用分数历史记录来判断是否是误报。Frigate 至少需要 3 帧才能确定它认为的目标类型，且中位数分数必须大于阈值。如果一个人在进入你的门廊前在人行道上达到此阈值，你将在他们单脚踏入区域的瞬间收到警报。

> 我认为这个功能的主要目的是减少不必要区域发生画面变动时的 CPU 使用。

是的，但"不必要"的定义各不相同。我想忽略那些我知道绝对不是由感兴趣目标触发的画面变动区域。时间戳、树木、天空、屋顶。我不想忽略我想要追踪并知道去向的目标的画面变动。

> 对我来说，给我的遮罩任何填充都会导致很多我不感兴趣的人物检测。我住在城市里，相机捕捉到很多人行道。人们经常走过我的前门，人行道和实际走上我的门廊之间的边缘非常薄，所以我基本上遮罩掉了门廊精确轮廓之外的所有区域。这导致非常整洁的检测，但这些信息一直让我困惑。我只是想太多了吗？

这就是`必需区域`的用途。你应该定义一个区域（记住这是基于边界框底部中心评估的），并将其设为保存快照和片段所必需的（在 0.9.0 到 0.13.0 中称为事件，在 0.14.0 及以后称为回放条目）。你也可以在通知条件中使用它。

> 也许我的具体情况就需要这样。我一直很难理解这些信息的相关性 - 似乎这正是"遮罩"任何图像区域时所期望的。

对你来说可能是这样。Frigate 肯定会更努力地追踪人行道上的人，以确保不会错过任何踏上你门廊的人。你现在的方式的权衡是目标识别速度较慢和可能的遗漏。根据你的需求，这可能是可以接受的。此外，如果你的检测流分辨率足够低，你的区域可能已经足够大，可以直接捕捉整个目标。
